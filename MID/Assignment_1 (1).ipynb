{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S5EDSFEvC7Sd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnY1ogJpC-yk",
        "outputId": "f7945af0-bde1-4f4a-8c24-f4ec1416b2db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1ISDDZGRC7Sf"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/Imagedata/Imagedata'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gjHFYYWC7Sg",
        "outputId": "01ecac5e-f973-47bc-e6b9-b3fcc49cdf6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [00:34<00:00,  1.58s/it]\n"
          ]
        }
      ],
      "source": [
        "# Load dataset with resizing images to the same dimensions\n",
        "def load_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_names = os.listdir(dataset_path)\n",
        "    for index, name in enumerate(tqdm(label_names)):\n",
        "        folder_path = os.path.join(dataset_path, name)\n",
        "        for image_name in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is not None:  # Check if the image was successfully loaded\n",
        "                image = cv2.resize(image, (224, 224))  # Resize images to 224x224 pixels\n",
        "                images.append(image)\n",
        "                labels.append(index)\n",
        "            else:\n",
        "                print(f\"Warning: Could not load image {image_path}\")\n",
        "    images = np.array(images, dtype='float32') / 255.0  # Normalize images\n",
        "    labels = np.array(labels)\n",
        "    labels = to_categorical(labels, num_classes=len(label_names))\n",
        "    return images, labels, label_names\n",
        "\n",
        "images, labels, label_names = load_dataset(dataset_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DHySto5DC7Sh"
      },
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ayr_B1X_C7Sh"
      },
      "outputs": [],
      "source": [
        "# Build CNN model\n",
        "def build_model(num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model(num_classes=len(label_names))\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msjnu0bYC7Si",
        "outputId": "697b6702-6791-4eb5-b1d3-5afcb39798d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 70s 7s/step - loss: 3.6886 - accuracy: 0.0508 - val_loss: 3.0446 - val_accuracy: 0.1562\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 59s 7s/step - loss: 2.8905 - accuracy: 0.1836 - val_loss: 2.9359 - val_accuracy: 0.1250\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 59s 7s/step - loss: 2.5166 - accuracy: 0.3047 - val_loss: 2.8145 - val_accuracy: 0.1719\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 59s 7s/step - loss: 2.1194 - accuracy: 0.4492 - val_loss: 2.7126 - val_accuracy: 0.1875\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 59s 7s/step - loss: 1.5673 - accuracy: 0.6562 - val_loss: 2.6283 - val_accuracy: 0.2500\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 58s 7s/step - loss: 1.0629 - accuracy: 0.7656 - val_loss: 2.5633 - val_accuracy: 0.2031\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 59s 8s/step - loss: 0.6224 - accuracy: 0.9102 - val_loss: 2.4843 - val_accuracy: 0.3125\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 64s 8s/step - loss: 0.3320 - accuracy: 0.9688 - val_loss: 2.4908 - val_accuracy: 0.3906\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 59s 7s/step - loss: 0.2060 - accuracy: 0.9805 - val_loss: 3.0338 - val_accuracy: 0.3125\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 2.6284 - val_accuracy: 0.3906\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 2.7708 - val_accuracy: 0.3594\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.7839 - val_accuracy: 0.3438\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.9335 - val_accuracy: 0.3281\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9613 - val_accuracy: 0.3281\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 59s 8s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.8680 - val_accuracy: 0.3594\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.9461 - val_accuracy: 0.3594\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9370 - val_accuracy: 0.3750\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.0244 - val_accuracy: 0.3438\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 59s 8s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0440 - val_accuracy: 0.3750\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 65s 8s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0511 - val_accuracy: 0.3750\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PMei3YSvC7Si"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def real_time_recognition(model, label_names):\n",
        "    # Initialize the webcam (use 0 as the parameter to select the default webcam)\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    # Check if the webcam is opened correctly\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(\"Cannot open webcam\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()  # Read a frame from the webcam\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess the frame for prediction (resize, expand dimensions, normalize)\n",
        "        face = cv2.resize(frame, (224, 224))  # Assuming your model expects 224x224 inputs\n",
        "        face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
        "        face = face / 255.0  # Normalize pixel values to [0, 1] as during training\n",
        "\n",
        "        prediction = model.predict(face)  # Make prediction\n",
        "        predicted_class = label_names[np.argmax(prediction)]  # Get the name of the predicted class\n",
        "\n",
        "        # Display the predicted class on the frame\n",
        "        cv2.putText(frame, predicted_class, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Show the frame\n",
        "        cv2.imshow('Real-time Face Recognition', frame)\n",
        "\n",
        "        # Break the loop when the 'q' key is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the webcam and close all OpenCV windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Assuming 'model' is your trained model and 'label_names' is a list of class names\n",
        "# real_time_recognition(model, label_names)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf 2.15 py3.9",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}